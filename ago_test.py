# 0.data preprocessing
def preprocessing_page():
    st.title("üõ†Ô∏è Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
    st.header("1Ô∏è‚É£ T·∫£i T·∫≠p D·ªØ Li·ªáu")
    uploaded_file = st.file_uploader("Ch·ªçn file CSV ƒë·ªÉ t·∫£i d·ªØ li·ªáu", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)

        # Hi·ªÉn th·ªã d·ªØ li·ªáu
        st.write("### üîç D·ªØ li·ªáu ban ƒë·∫ßu:")
        st.write(df.head())
        st.write(f"**S·ªë l∆∞·ª£ng m·∫´u:** {df.shape[0]}, **S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng:** {df.shape[1]}")

        # ==========================
        # 2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
        # ==========================
        st.sidebar.header("üõ†Ô∏è Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

        remove_missing = st.sidebar.checkbox("Lo·∫°i b·ªè gi√° tr·ªã thi·∫øu")
        standardize = st.sidebar.checkbox("Chu·∫©n h√≥a d·ªØ li·ªáu (StandardScaler)")
        remove_outliers = st.sidebar.checkbox("X·ª≠ l√Ω gi√° tr·ªã ngo·∫°i lai (IQR)")
        filter_noise = st.sidebar.checkbox("X·ª≠ l√Ω nhi·ªÖu (L·ªçc trung b√¨nh)")
        encode_labels = st.sidebar.checkbox("M√£ h√≥a nh√£n (Label Encoding)")

        # ==========================
        # 3. N√∫t Ti·ªÅn X·ª≠ L√Ω
        # ==========================
        if st.sidebar.button("üöÄ Ti·∫øn h√†nh Ti·ªÅn X·ª≠ L√Ω"):
            # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
            if remove_missing:
                # 1. X·ª≠ l√Ω gi√° tr·ªã thi·∫øu
                df["Age"].fillna(df["Age"].median(), inplace=True)  # ƒêi·ªÅn median cho Age
                df["Discount"].fillna(0, inplace=True)  # ƒêi·ªÅn 0 cho Discount
                df["OrderDate"] = pd.to_datetime(df["OrderDate"]).fillna(pd.Timestamp("2021-01-01"))  # ƒêi·ªÅn gi√° tr·ªã m·∫∑c ƒë·ªãnh cho OrderDate
                df["City"].fillna("Unknown", inplace=True)  # ƒêi·ªÅn "Unknown" cho City
                df["Rating"].fillna(df["Rating"].mean(), inplace=True)  # ƒêi·ªÅn gi√° tr·ªã trung b√¨nh cho Rating
                st.success("‚úÖ ƒê√£ lo·∫°i b·ªè gi√° tr·ªã thi·∫øu.")

            if standardize:
                scaler = StandardScaler()
                X = pd.DataFrame(scaler.fit_transform(X), columns=data.feature_names)
                st.success("‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu.")

            if remove_outliers:
                # Ph√°t hi·ªán v√† lo·∫°i b·ªè ngo·∫°i lai s·ª≠ d·ª•ng IQR
                Q1 = df.quantile(0.25)
                Q3 = df.quantile(0.75)
                IQR = Q3 - Q1
                X = X[~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)]
                st.success("‚úÖ ƒê√£ x·ª≠ l√Ω gi√° tr·ªã ngo·∫°i lai (IQR).")

            if filter_noise:
                # √Åp d·ª•ng b·ªô l·ªçc trung b√¨nh ƒë·ªÉ x·ª≠ l√Ω nhi·ªÖu
                X = X.rolling(window=3, min_periods=1).mean()
                st.success("‚úÖ ƒê√£ x·ª≠ l√Ω nhi·ªÖu (l·ªçc trung b√¨nh).")

            if encode_labels:
                encoder = LabelEncoder()
                y = encoder.fit_transform(y)
                st.success("‚úÖ ƒê√£ m√£ h√≥a nh√£n.")

            st.write("### üõ†Ô∏è D·ªØ li·ªáu sau ti·ªÅn x·ª≠ l√Ω:")
            st.write(X.head())